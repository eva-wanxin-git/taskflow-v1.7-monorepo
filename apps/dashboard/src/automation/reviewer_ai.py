"""
å®¡æŸ¥è€… AI æ¨¡å—

è´Ÿè´£ä»£ç å®¡æŸ¥ã€è¯„åˆ†åé¦ˆã€å†³å®šé€šè¿‡/ä¿®è®¢
"""

import json
import time
from typing import Dict, List, Any, Optional
from datetime import datetime

from anthropic import Anthropic

from .models import Task, TaskStatus, Review, ReviewScore
from .state_manager import StateManager
from .config import config


class ReviewerAI:
    """å®¡æŸ¥è€…AI - è´Ÿè´£ä»£ç å®¡æŸ¥å’Œè¯„åˆ†
    
    å·¥ä½œæµ:
    1. ç›‘å¬å¾…å®¡æŸ¥ä»»åŠ¡ï¼ˆreviewçŠ¶æ€ï¼‰
    2. è¯»å–ä»»åŠ¡ä»£ç å’Œè¦æ±‚
    3. è°ƒç”¨Claudeè¿›è¡Œå®¡æŸ¥
    4. è§£æå®¡æŸ¥ç»“æœ
    5. ä¿å­˜å®¡æŸ¥è®°å½•
    6. æ›´æ–°ä»»åŠ¡çŠ¶æ€
    7. å¦‚éœ€ä¿®è®¢ï¼Œè‡ªåŠ¨åˆ›å»ºä¿®è®¢ä»»åŠ¡
    """
    
    def __init__(self, state_manager: StateManager):
        """åˆå§‹åŒ–å®¡æŸ¥è€…AI
        
        Args:
            state_manager: çŠ¶æ€ç®¡ç†å™¨å®ä¾‹
        """
        self.state_manager = state_manager
        self.client = Anthropic(api_key=config.get('claude.api_key'))
        self.model = config.get('claude.reviewer_model', config.get('claude.pm_model'))
        self.max_tokens = config.get('claude.max_tokens', 4096)
        self.pass_score = config.get('review.pass_score', 80)
        
        # åŠ è½½æç¤ºè¯
        self.system_prompt = self._load_prompt()
    
    def _load_prompt(self) -> str:
        """åŠ è½½ç³»ç»Ÿæç¤ºè¯
        
        Returns:
            æç¤ºè¯å†…å®¹
        """
        try:
            with open('automation-config/reviewer_prompt.md', 'r', encoding='utf-8') as f:
                return f.read()
        except FileNotFoundError:
            return "You are a code reviewer AI responsible for code review and scoring."
    
    def review_task(self, task: Task) -> Optional[Review]:
        """å®¡æŸ¥ä»»åŠ¡
        
        Args:
            task: å¾…å®¡æŸ¥çš„ä»»åŠ¡
            
        Returns:
            å®¡æŸ¥è®°å½•ï¼Œå¦‚æœå®¡æŸ¥å¤±è´¥è¿”å›None
        """
        try:
            # è·å–ä»»åŠ¡ä¿¡æ¯
            task_info = f"""
ä»»åŠ¡ID: {task.id}
ä»»åŠ¡æ ‡é¢˜: {task.title}
ä»»åŠ¡æè¿°: {task.description}
é¢„ä¼°å·¥æ—¶: {task.estimated_hours}å°æ—¶
å¤æ‚åº¦: {task.complexity}
            """
            
            # æ„å»ºå®¡æŸ¥æç¤º
            review_prompt = f"""
è¯·å¯¹ä»¥ä¸‹ä»»åŠ¡è¿›è¡Œä»£ç å®¡æŸ¥ï¼Œå¹¶æŒ‰ç…§å®¡æŸ¥æ ‡å‡†è¿›è¡Œè¯„åˆ†ã€‚

{task_info}

è¦æ±‚ï¼š
1. æ ¹æ®åŠŸèƒ½å®Œæ•´æ€§ã€ä»£ç è´¨é‡ã€è§„èŒƒéµå®ˆã€æ–‡æ¡£å®Œæ•´ã€æµ‹è¯•è¦†ç›–äº”ä¸ªç»´åº¦è¯„åˆ†
2. æ€»åˆ†100åˆ†ï¼Œè®¡ç®—å„ç»´åº¦åˆ†æ•°å’Œå’Œ
3. 80åˆ†åŠä»¥ä¸Šä¸ºé€šè¿‡ï¼Œä½äº80åˆ†ä¸ºéœ€ä¿®è®¢
4. è¿”å›æœ‰æ•ˆçš„JSONæ ¼å¼

è¯„åˆ†æ ‡å‡†ï¼š
- åŠŸèƒ½å®Œæ•´æ€§ (30åˆ†)
- ä»£ç è´¨é‡ (25åˆ†)
- è§„èŒƒéµå®ˆ (20åˆ†)
- æ–‡æ¡£å®Œæ•´ (15åˆ†)
- æµ‹è¯•è¦†ç›– (10åˆ†)

è¿”å›JSONæ ¼å¼:
{{
  "functionality_score": <æ•°å­—>,
  "code_quality_score": <æ•°å­—>,
  "standards_score": <æ•°å­—>,
  "documentation_score": <æ•°å­—>,
  "testing_score": <æ•°å­—>,
  "total_score": <æ•°å­—>,
  "passed": <true/false>,
  "feedback": "<åé¦ˆæ„è§>",
  "revision_instructions": "<ä¿®è®¢æŒ‡ä»¤æˆ–null>"
}}
"""
            
            # è°ƒç”¨Claudeè¿›è¡Œå®¡æŸ¥
            response = self.client.messages.create(
                model=self.model,
                max_tokens=self.max_tokens,
                system=self.system_prompt,
                messages=[{"role": "user", "content": review_prompt}]
            )
            
            result_text = response.content[0].text
            
            # è§£æå®¡æŸ¥ç»“æœ
            review_result = self._parse_review_result(result_text, task)
            
            if review_result:
                # ä¿å­˜å®¡æŸ¥è®°å½•
                success = self.state_manager.create_review(review_result)
                
                if success:
                    # æ›´æ–°ä»»åŠ¡çŠ¶æ€
                    if review_result.score.passed:
                        self.state_manager.update_task_status(task.id, TaskStatus.COMPLETED)
                    else:
                        self.state_manager.update_task_status(task.id, TaskStatus.REVISION)
                        # åˆ›å»ºä¿®è®¢ä»»åŠ¡
                        self._create_revision_task(task, review_result)
                    
                    return review_result
            
            return None
        
        except Exception as e:
            print(f"[ReviewerAI] âœ— å®¡æŸ¥å¤±è´¥: {str(e)}")
            return None
    
    def _parse_review_result(self, result_text: str, task: Task) -> Optional[Review]:
        """è§£æå®¡æŸ¥ç»“æœ
        
        Args:
            result_text: Claudeè¿”å›çš„æ–‡æœ¬
            task: è¢«å®¡æŸ¥çš„ä»»åŠ¡
            
        Returns:
            å®¡æŸ¥è®°å½•å¯¹è±¡
        """
        try:
            # æå–JSON
            json_start = result_text.find('{')
            json_end = result_text.rfind('}') + 1
            json_str = result_text[json_start:json_end]
            data = json.loads(json_str)
            
            # åˆ›å»ºè¯„åˆ†å¯¹è±¡
            score = ReviewScore(
                functionality=data.get('functionality_score', 0),
                code_quality=data.get('code_quality_score', 0),
                standards=data.get('standards_score', 0),
                documentation=data.get('documentation_score', 0),
                testing=data.get('testing_score', 0),
            )
            
            # åˆ›å»ºå®¡æŸ¥è®°å½•
            review_id = f"review-{task.id}-{datetime.now().strftime('%Y%m%d%H%M%S')}"
            
            decision = "approved" if score.passed else "revision_required"
            
            review = Review(
                id=review_id,
                task_id=task.id,
                reviewer_id="reviewer-ai",
                score=score,
                feedback=data.get('feedback', ''),
                decision=decision,
                created_at=datetime.now()
            )
            
            return review
        
        except (json.JSONDecodeError, KeyError, ValueError) as e:
            return None
    
    def _create_revision_task(self, task: Task, review: Review) -> bool:
        """åˆ›å»ºä¿®è®¢ä»»åŠ¡
        
        Args:
            task: åŸä»»åŠ¡
            review: å®¡æŸ¥ç»“æœ
            
        Returns:
            æ˜¯å¦åˆ›å»ºæˆåŠŸ
        """
        try:
            # ç”Ÿæˆä¿®è®¢ä»»åŠ¡ID
            parts = task.id.split('.')
            if len(parts) == 2:
                major, minor = parts[0].split('-')[1], parts[1]
                revision_id = f"task-{major}.{int(minor) + 1}"
            else:
                revision_id = f"{task.id}-revision"
            
            # åˆ›å»ºä¿®è®¢ä»»åŠ¡
            revision_task = Task(
                id=revision_id,
                title=f"{task.title} (ä¿®è®¢ç‰ˆ)",
                description=f"""åŸä»»åŠ¡ï¼š{task.title}

å®¡æŸ¥åé¦ˆï¼š
{review.feedback}

ä¿®è®¢è¦æ±‚ï¼š
{review.feedback}

ä¿®è®¢æŒ‡ä»¤ï¼š
è¯·æ ¹æ®ä¸Šè¿°å®¡æŸ¥åé¦ˆè¿›è¡Œä¿®æ”¹å’Œæ”¹è¿›ã€‚
""",
                status=TaskStatus.PENDING,
                priority=task.priority,
                complexity=task.complexity,
                estimated_hours=task.estimated_hours * 0.8,
                depends_on=[task.id],  # ä¾èµ–åŸä»»åŠ¡
            )
            
            # ä¿å­˜ä¿®è®¢ä»»åŠ¡
            return self.state_manager.create_task(revision_task)
        
        except Exception as e:
            return False
    
    def auto_review_loop(self, poll_interval: int = 30) -> None:
        """è‡ªåŠ¨å®¡æŸ¥å¾ªç¯
        
        Args:
            poll_interval: è½®è¯¢é—´éš”ï¼ˆç§’ï¼‰
        """
        print(f"[ReviewerAI] ğŸš€ å¯åŠ¨è‡ªåŠ¨å®¡æŸ¥å¾ªç¯...")
        
        while True:
            try:
                # è·å–æ‰€æœ‰å¾…å®¡æŸ¥ä»»åŠ¡
                review_tasks = self.state_manager.list_tasks_by_status(TaskStatus.REVIEW)
                
                for task in review_tasks:
                    print(f"[ReviewerAI] ğŸ“ å®¡æŸ¥ä»»åŠ¡: {task.id}")
                    
                    # è¿›è¡Œå®¡æŸ¥
                    review = self.review_task(task)
                    
                    if review:
                        if review.score.passed:
                            print(f"[ReviewerAI] âœ“ å®¡æŸ¥é€šè¿‡ ({review.score.total}åˆ†)")
                        else:
                            print(f"[ReviewerAI] ğŸ”§ éœ€è¦ä¿®è®¢ ({review.score.total}åˆ†)")
                    else:
                        print(f"[ReviewerAI] âœ— å®¡æŸ¥å¤±è´¥")
                
                # ç­‰å¾…ä¸‹ä¸€è½®
                time.sleep(poll_interval)
            
            except KeyboardInterrupt:
                print(f"[ReviewerAI] â¹ï¸  åœæ­¢å®¡æŸ¥å¾ªç¯")
                break
            except Exception as e:
                print(f"[ReviewerAI] âœ— å¾ªç¯é”™è¯¯: {str(e)}")
                time.sleep(poll_interval)
    
    def generate_review_report(self, review: Review) -> str:
        """ç”Ÿæˆå®¡æŸ¥æŠ¥å‘Š
        
        Args:
            review: å®¡æŸ¥è®°å½•
            
        Returns:
            æŠ¥å‘Šæ–‡æœ¬
        """
        score = review.score
        
        report = f"""# ä»£ç å®¡æŸ¥æŠ¥å‘Š - {review.task_id}

**å®¡æŸ¥è€…**: {review.reviewer_id}  
**å®¡æŸ¥æ—¶é—´**: {review.created_at.isoformat()}  
**å®¡æŸ¥ID**: {review.id}

---

## ğŸ“Š è¯„åˆ†ç»“æœ

| ç»´åº¦ | å¾—åˆ† | æ»¡åˆ† | æ¯”ä¾‹ |
|------|------|------|------|
| åŠŸèƒ½å®Œæ•´æ€§ | {score.functionality} | 30 | {score.functionality/30*100:.0f}% |
| ä»£ç è´¨é‡ | {score.code_quality} | 25 | {score.code_quality/25*100:.0f}% |
| è§„èŒƒéµå®ˆ | {score.standards} | 20 | {score.standards/20*100:.0f}% |
| æ–‡æ¡£å®Œæ•´ | {score.documentation} | 15 | {score.documentation/15*100:.0f}% |
| æµ‹è¯•è¦†ç›– | {score.testing} | 10 | {score.testing/10*100:.0f}% |
| **æ€»åˆ†** | **{score.total}** | **100** | **{score.total}%** |

---

## âœ… å®¡æŸ¥ç»“æœ

**çŠ¶æ€**: {'âœ… é€šè¿‡' if score.passed else 'ğŸ”§ éœ€è¦ä¿®è®¢'}  
**å†³å®š**: {review.decision}  
**æ˜¯å¦åˆå¹¶**: {'æ˜¯' if score.passed else 'å¦'}

---

## ğŸ’¬ å®¡æŸ¥æ„è§

{review.feedback}

---

## ğŸ”§ ä¿®è®¢å»ºè®®

{review.feedback if not score.passed else 'æ— éœ€ä¿®è®¢'}

---

**å®¡æŸ¥å®Œæˆ**
"""
        
        return report
